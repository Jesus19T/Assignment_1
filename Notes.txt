Due October 9

Schedule: 
Unigram  & Bigram : September 24
Smoothing & Perpexity: September 28 
Report: September 29

Questions: 
1. How to deal with contraction words  (I 'm, do n't, did n't)  
2. How to deal with numbers/dates (10-1... 11/10/2023)
3. Should we remove stop words? 

versions: 
v1.0 = only words
v2.0 = words + numbers


Things to improve for assignment: 
1. What do we use the probabilities for? 
2. How do we show/evaluate the models? 


Preprocessing - 
- remove punctuation 
- make everything lowercase
- append start (<s>) and end  (<STOP>) tokens

Part 3: 
Unsmooothed n-grams
- get the probability of unigram and bigram for the whole file
- unigram
	- train: 
		- parse the words
		- space as the delimiter
		- create a dictionary (key-value) 
		- calculate probability
	- validate: 
		- for each sentence - calculate the probabilities 
	
- bigram 
	- train: 
		- parse phrases as bigrams into a dictionary? (key-value) 
		- calculate probability for each 
	
	- validate: 
		- for each sentence - calculate the probabilities 
	
	
Part 4: 
Smoothing and unknown words
1. Laplace
2. Add-k smoothing


Part 5: 
Perplexity
